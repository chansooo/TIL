# CH 11-2. Disk Scheduling

### 디스크 성능을 결정하는 요소

1. Computer System
2. Operationg system
3. The nature of the IO channel
4. Disk Controller hardware.

![스크린샷 2022-06-12 03.02.29.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-12_03.02.29.png)

- **Access time  = seek time + rotational delay**
1. Device를 기다리고
2. Device할당 받고 Channel을 기다리고
3. Seek(찾고)
4. 회전지연 기다리고
5. 전송시간까지 기다리고

Device Busy = Wait for Channel + Seek + Rotational Delay + Data Transfer

### Seek Time : 첫번째 파라미터

요구한 Track까지 Disk Arm이 도착하는데 걸리는 시간

- 두 가지 핵심요소
    - 초기 시작시간 : arm을 준비
    - 순회(traversal) 시간
        
        : disk arm이 최대 속도에 도달한 후 트랙을 순회하는데 걸리는 시간
        
        - 선형 시간이 아니다! 왜냐면! 밑의 올바른 트랙에 왔는지 식별을 하는 시간까지 포함하기 때문!
        - 올바른 트랙에 도착했는지 식별이 끝날 때까지의 시간도 포함하기 때문에
- Seek Time은 많은 개선이 이루어졌다
    - 기술 발전에 따라 디스크의 크기가 작아졌고, 최신 HDD의 평균 Seek Time은 10ms 미만이다.

### Rotational Delay(회전지연) : 두번째 파라미터

: 디스크의 지정된 영역이 회전하는데 필요한 시간

(해당 트랙에 도착한 이후에 해당 섹터를 찾는 시간)

- 평균 rotational delay = 회전 시간(한바퀴도는데 걸리는시간) * 1/2
    
    ex) 15000rpm → 60(초)/15000 * 1000(밀리) * 1/2 = 2ms → 회전지연시간!
    

→ 분당 15000번돈다. 1초 = 1000밀리세컨드

### 전송 시간과 타이밍 비교

- b = 전송할 바이트 수(전송 되어질 파일의 크기)
- N = 트랙의 바이트 수(트랙당 바이트수)
- r = 초당 회전 속도
- 전송 시간
    
    ![스크린샷 2022-06-13 00.46.35.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-13_00.46.35.png)
    

- 전체 평균 접근 시간
    
    ![스크린샷 2022-06-13 00.46.14.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-13_00.46.14.png)
    
    - Ts : avg. seek time
    - 1/(2r) : rotational delay
    - b/(rN) : data transfer

- 예시
    - 평균 seek time : 4ms
    - 회전속도 : 7500rpm
    - 512B의 500개의 섹터로 구성된 트랙
    
    Q. 연속적으로 2500개의 섹터가 있을 경우는?
    
    - 첫번째 트랙에 찾아 가는 시간
        
        4ms(탐색시간)+ 4ms(회전지연) + 8ms(500섹터 읽는 시간 → 한 바퀴 도는데 걸리는 시간 == 회전지연시간 *2) = 16ms
        
    - 이후 연속된 트랙에서 걸리는 시간
        
        탐색시간이 필요없다.
        
        4ms(회전지연) + 8ms(500섹터 읽는 시간) = 12ms
        
    - 총합
        
        16ms (첫 500섹터) + (4 * 12)ms (이후 2000 섹터) = 64ms
        
    
    Q. 만약 연속되지 않고 무작위 위치에 섹터가 있다면?
    
    위에서 계산한 것을 토대로 구해본다.
    
     한 섹터를 읽는 시간 : (8ms / 500 = 0.016ms) + 4ms(탐색시간) + 4ms(회전지연) = 8.016ms
    
    8.016ms * 2500 = 20040m = 20.04초
    

## 디스크 스케줄링 정책

---

### Requestor에 따른 선택 정책

- Random
- **FIFO(first in first out~!)**
    - 큐에서 순차적으로 처리된다.
    - 적합한 경우 : 프로세스 수가 적을 때, 파일 섹터가 클러스터를 이루고 있을 때(파일들이 모여있을떄!!!)
    - 안좋은 경우 : 프로세스가 많을 때 → Random과 비슷해진다.
- **PRI (Priority)**
    - 디스크 사용율의 최적화가 목표가 아니다
        
        → 디스크 관리 소프트웨어의 제어 밖의 영역이다
        
    - 짧은 배치 job과 대화형 job은 높은 우선순위를 가진다
        
        → 좋은 response time
        
    - 긴 job은 지나치게 오래 기다려야 할 수 있다.
- **LIFO(Last In First Out)** : 지역성 원칙에 의한 자원 활용 극대화

### 요청된 item에 따른 선택 정책

- **SSTF (Shortest Service Time First)**
    - 현재 디스크 암의 위치에서 최단 거리의 위치에 있는놈을 먼저 처리 하겠다
    - 평균 seek time의 최소를 보장하지 않는다
    - 하지만 FIFO보다는 좋은 성능을 낸다
    - 가까운 위치만 계속 탐색하면서 멀리 있는 트랙에 기아상태가 발생할 수 있다.
- **SCAN** : 한 쪽 방향으로 이동
    - 엘리베이터 알고리즘이라고도 불린다(한방향으로 올라갔다가 내려갔다가 이런식으로 작동)
    - SSTF만큼 지역성 관점에서 좋지는 않지만, 기아상태를 예방할 수 있다.
    - **LOOK policy**
        
        : 해당 방향으로 더 이상 요청이 없으면 마지막 트랙에 도달하지 않아도 방향을 반대로 바꾼다.
        
- **C-SCAN (Circular SCAN)**
    - SCAN의 문제를 보완한 방식(SCAN의 문제? 좀 멀면 좀 기다려야함)
        - 탐색이 지나간 위치에 새로운 요청이 생기면 오래 지연된다.
    - 한 방향으로만 스캔하도록 제한한다
        - SCAN이 0 → MAX → 0 이었다면 C-SCAN은 0 → MAX, 0 → MAX
    - interval = s_max + t
        - t : 안쪽 트랙(0)에서 바깥 트랙 방향으로 탐색하면서 걸리는 시간
        - s_max : 탐색 시간의 최대 (max seek time)
    - SCAN은 interval이 2t까지 발생 가능(끝에서 끝 하면 2t임)
- **N-step-SCAN**
    - SSTF, SCAN, C-SCAN에서는 “arm stickiness” 문제가 발생할 수 있다
        - 특정 트랙 또는 근처에 지속적으로 요청이 발생 → 기아상태가 발생 가능
        - ex) A → B → C 트랙이 C-SCAN에 의해 순서대로 탐색되어야 하는데, A-B 사이에 계속 새로운 요청이 들어온다
    - 따라서 디스크 요청 큐를 N 크기로 분할한다
        
        → 중간에 요청이 더 오더라도 N개만 처리한다
        
        ⇒ N 안에 응답해줄 수 있다.
        
    - N 크기에 대한 고려사항
        - 너무 커지면? SCAN과 비슷해진다
        - 1에 가까워진다? FIFO와 비슷해진다
- **FSCAN (Freezing SCAN)**
    - 두 개의 서브큐를 사용한다
    - 스캔하는 동안에 요청된 것들은 다른 큐에 넣는다.
        
        ⇒ 새로운 요청은 이전 요청이 모두 완료될 때까지 기다린다.
        
        ⇒ 그러면 한쪽 큐를 스캔하는 시작시점에는 다른쪽 큐는 비어있다.(이래서 Freezing이라고한대..)
        
    - N-step-SCAN과의 비교
        - 응답시간 : N-step-SCAN이 더 좋다 (N 안에 응답이 보장)
        - 평균 탐색시간 : FSCAN이 지역성을 더 활용하여 적다.

## RAID (Redundant Array of Independent Disks)

---

설계 고려 사항

1. 여러개의 물리적 디스크 드라이버를 OS에 의해 하나의 논리적 드라이브처럼 보이도록 지원해야 한다.
2. Striping 기법을 이용해서 데이터를 분산해서 저장한다.
3. 패리티 정보를 이용해서 디스크 고장시에 복구할 수 있도록 한다.

- RAID 0 ~ 6의 레벨로 구성된다. → 0 , 1은 패리티 정보 안가진다.

### RAID

- 여러개의 디스크를 사용하며 여러 드라이브의 데이터에 동시에 접근할 수 있도록 데이터를 분산해서 저장한다.
    - IO 성능이 향상된다(동시에 접근 가능하니까!!)
    - 용량을 쉽게 늘릴 수 있다(그냥 디스크 하나 더 추가해버리면됨)

- 장점
    - Redundancy (중복, 여분)의 필요성을 효과적으로 해결한다. → 신뢰성
    - 패리티 정보를 이용해서 데이터 복구가 가능하다 (디스크 장애로 인한 손실이 발생했을 때)
    - 디스크의 여러 head와 actuator가 동시에 돌아가게 하여 IO 성능을 높인다
- 단점
    - 여러 장치를 사용하므로 고장 확률이 높아진다

### RAID Level 0 → 중복성 제공 X(Redundancy)

![스크린샷 2022-06-12 04.49.11.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-12_04.49.11.png)

- Redundancy(중복)를 포함하지 않기 때문에 진정한 RAID는 아니다.
    
    → 데이터 보호를 제공하지 못한다
    
- **Striping**을 지원한다.
    
    **Striping : 데이터를 모든 디스크에 분산해서 저장**
    
- 하나의 IO 요청이 여러 개의 Strip으로 구성되어 있으면 병렬 처리가 가능 → IO 전송 시간 크게 단축

### RAID Level 1 (미러링)

![스크린샷 2022-06-12 04.55.25.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-12_04.55.25.png)

- **Mirroring**
    
    : 모든 디스크에는 동일한 데이터가 저장된 미러 디스크가 있다.
    
- 미러 디스크도 Striping되어 있기 때문에 “write penalty”가 발생하지 않는다
    
    원본 디스크에 쓰면서 병렬적으로 동시에 미러 디스크에도 쓰면 되기 때문에
    
- 드라이브에 장애가 발생하면 Copy해서 썼던 second drive(회색)에서 데이터를 가져올 수 있다.

- 단점 : 비용
    - 사용할 수 있는 용량이 반으로 줄어든다
    
    → 시스템 데이터나 중요한 파일에만 미러링을 사용한다.
    
    ex) OS → RAID Level 1을 쓴다!
    

### RAID Level 2 (해밍 코드를 이용한 redundancy)

![스크린샷 2022-06-12 04.59.21.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-12_04.59.21.png)

- 디스크 헤더가 동시간에 동기화를 통해 각 디스크의 동일한 지점을 가리키고 있다.
- 모든 멤버 디스크가 모든 IO 요청 실행에 참여한다
    - 모든 디스크가 동일한 트랙, 동일한 섹터에 데이터를 저장하고 불러온다.
- 데이터 Striping을 사용한다
- Hamming code를 사용하여 단일 비트 오류 및 이중 비트 오류를 검출한다
- 패리티 사용.
- 디스크 오류가 많이 발생하는 환경에서 효과적이다
    - 하지만 디스크의 신뢰성이 많이 높아졌기 때문에 RAID 2를 많이 사용하지 않는다

### RAID Level 3 (비트 패리티)

![스크린샷 2022-06-12 05.01.14.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-12_05.01.14.png)

- 디스크 개수에 상관없이 패리티 디스크 하나만 존재한다. → 공간활용이 아주 좋다.
- IO 요청에 대해 모든 디스크가 사용되므로 **동시간에 하나의 IO만 처리**할 수 있다.
- 모든 디스크의 동일한 위치 비트를 XOR한 패리티 비트를 저장한다.
    - 디스크 0~3과 패리티 디스크 4가 있을 때 만약 디스크 1에서 오류가 발생했다면?
        
        X4 = X3 XOR X2 XOR X1 XOR X0 이므로
        
        양변에 X4 XOR X1을 하면 (XOR 연산) X4 XOR X4 = 1
        
        X1 = X4 XOR X3 XOR X2 XOR X0
        
        → 그니까 복구하고 싶은 디스크 빼고 나머지 다 XOR하면 된다! (패리티 디스크 포함)
        

---

4 ~ 6은 Independent Access를 사용한다.

### RAID Level 4 (블록 수준 패리티)

![스크린샷 2022-06-12 05.17.59.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-12_05.17.59.png)

- RAID 0 ~ 3은 모든 디스크에 병렬적으로 처리를 했었지만, 4 ~ 6은 독립적인 액세스를 사용한다.
    
    → 여러 IO를 독립적으로 처리하여서 병렬 처리한다.
    
- 적합 : 높은 IO request rate를 요구할 때
- 부적합 : 높은 데이터 전송 속도를 요구할 때 적합하지 않다!!!
- 블록 단위의 Striping을 사용한다.(Striping 단위가 크다)
    - block0 ~ 3수정하면 P(0~3)을 수정
- 패리티 디스크의 병목 현상이 발생할 수 있다.
    - why? RAID 3에서는 하나의 IO에 대해 패리티를 썼지만, RAID 4는 여러 IO 작업을 병렬처리하기 때문에 디스크가 독립적이더라도 패리티를 업데이트하기 위해서 기다리게 된다.
    
    → 시스템 저하 발생 가능
    

- 헷갈리는 개념
    - RAID 0 ~ 3의 병렬은 하나의 IO 요청을 병렬적으로 처리
    - RAID 4 ~ 6의 병렬은 여러 IO 요청을 병렬적으로 처리

### RAID Level 5 (블록 수준 분산 패리티)

![스크린샷 2022-06-12 05.18.54.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-12_05.18.54.png)

- RAID 4에서 하나의 패리티 디스크를 사용해서 병목현상이 발생하였다
- 따라서 **패리티를 모든 디스크에 분산**시킨다.
    
    → 병목현상을 방지한다.
    

### RAID Level 6 (블록 수준 이중 분산 패리티)

![스크린샷 2022-06-12 05.21.00.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-12_05.21.00.png)

- 두 개의 서로 다른 패리티 계산을 수행해서 모든 디스크에 분산하여 저장한다.
    - XOR 알고리즘
    - data check 알고리즘
    
    → 두 개의 디스크가 고장나도 복구시킬 수 있다. → 안전성을 제공.
    
- 쓰기마다 두 개의 패리티에 영향 → 상당한 쓰기 패널티 발생
    
    ⇒ RAID 5에 비해 전체 쓰기 성능이 30% 이상 하락한다
    

### RAID 레벨에 따른 비교

![스크린샷 2022-06-12 05.24.10.png](CH%2011-2%20Disk%20Scheduling%20864f9976160a4d9db85fd1405aadfb59/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-12_05.24.10.png)

## Disk Cache

---

디스크 섹터용 메모리의 버퍼

디스크가 메인메모리에 접근하고 가져오는데 좀 성능저하가 있어서 미리 불러와서 올려놓는다. → 디스크캐시.

- IO 요청이 있을 때 해당 섹터가 디스크 캐시에 있는지 확인한다
    - 있다면 → 캐시에서 요청을 처리
    - 없다면 → 요청된 섹터를 디스크로부터 디스크 캐시에 불러온다
- 설계 고려사항
    - 디스크 캐시의 데이터를 요청 프로세스에 어떻게 전달할 것인가?
        1. 프로세스가 할당된 메모리에 복사해주기
        2. 디스크 캐시에 해당 위치의 포인터를 전달하기(속도 훨씬 빠름)
    - 적합한 교체 정책은?

### Least Recently Used (LRU)

- 교체 방식에서 가장 일반적으로 사용되는 알고리즘
- 캐시에서 가장 오래 참조되지 않은 블록을 교체
- 블록을 이동시키지 않고 캐시를 참조하는 포인터 스택을 사용해서 구현한다
    - 가장 최근에 참조된 블록은 스택의 top에 있다
    - 블록이 참조되거나 캐시로부터 불러올 때 스택의 top으로 이동한다.
    - 스택의 제일 밑에 있는놈을 교체 대상으로 선택한다!

### Least Frequently Used (LFU)

- 가장 참조가 적은 블록을 교체
- Counter가 각 블록에 연결되어 있어서 블록에 액세스(접근)할 때마다 증가시킨다
- count가 가장 적은 블록이 선택해서 교체해버린다.

- 문제점
    - 블록이 실제로 자주 쓰이는 것이 아니라, 지역성으로 인해 짧은 간격동안 많은 참조가 일어났을 때
        
        → 필요하지 않은데 메모리에 남아있게 된다.