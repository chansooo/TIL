# VM- Hardware

# 8-1 하드웨어와 제어구조

## 가상메모리 관련 핵심용어

1. Virtual Memory
    - 보조기억장치를 주기억장치처럼 주소지정하게 만든 저장공간 할당체제.
    - 프로그램이 가상메모리를 참조할 때 사용하는 주소는 메모리시스템이 물리메모리의 특정위치를 식별할 때 사용하는 주소와 구별된다.
    - 프로그램이 생성한 가상메모리 주소는 그에 대응되는 물리주소로 자동변환된다.
    - 가상메모리의 크기는 메인메모리의 크기가 아니라 **컴퓨터시스템의 주소지정체제**와 **보조기억장치의 가용공간**에 의해 제한된다.(메인메모리 크기보다 훨씬 크게 가질 수 있다)
2. Virtual Address - 가상메모리에서의 Address
    - 메인메모리처럼 참조될 수 있도록 가상메모리의 특정위치에 배정된 주소
3. Virtual Address Space
    - 프로세스가 할당받은 가상 주소(Virtual Address)의 영역(Storage)
4. Address Space
    - 프로세스가 물리적주소, 실제 주소에 접근할 수 있는 영역(Range)
5. Real Address - 메인메모리에서의 Address 
    - 메인메모리의 특정 저장위치(Storage Location)의 주소.

## 페이징과 세그멘테이션의 특징 2가지

1. 프로세스의 모든 메모리 참조는 논리주소(Logical Address)이고 이 논리주소는 프로세스 Run-time에 동적으로(Dynamic) 하드웨어를 통해 물리주소(Physical Address)로 바뀐다. 
바로 사용 가능하다! 피지컬 어드레스는!
2. 프로세스가 실행될 때 분할되는 조각들(Page, Segment)은 메인메모리의 연속된 영역에 위치할 필요가 없다.

→ 만약 저 위의 2가지 특성이 만족된다면, 프로세스가 수행 될 때 프로세스의 모든 페이지 or 세그먼트는 메인메모리에 있을 필요가 없다.

→ 필요한 녀석들만 올려놓고 수행하면됨.

### 프로세스 실행에서 어떠한 이점이 있을까?

- 운영체제는 프로그램이 필요한 Page or Segment만 메인메모리로 불러와서 실행시키면 됨.
    - 시간을 Save! 모든것을 복사안하고 필요한것만 쓰고 안쓰는 조각(PorS)들을 Swappe in/out 안해도됨.
- **Resident Set**(상주집합, 적재집합) : The portion of process(프로세스의 부분) 중 메인메모리에 올라와 있는 조각
- **Memory Access Fault** : 메인메모리에 적재되지 않은, 적재집합에 없는 부분의 논리주소가 참조될 경우 Memory Access Fault 인터럽트를 발생시킴.

### **Memory Access Fault 인터럽트 과정**

1. 인터럽트 당한 프로세스를 Block상태로 바꾼다.
2. OS가 Disk I/O를 요청.
3. 다른 프로세스에게 CPU를 넘겨 디스크 입출력이 진행되는 동안 수행될 수 있게끔한다.
    - 하드웨어 퍼포먼스를 올리기 위해.
4. 요청한 Disk I/O가 끝나면 제어권을 프로세스에서 OS로 넘기게 되고 Memory Access Fault 인터럽트로 Block되었던 Process를 Ready로 바꾼다.

### Memory Access Fault에 대한 의구심

- 음... 이렇게 하면 메인메모리에 없는 부분때문에 자주 인터럽트 당하지 않을까?
- 하지만 그냥 일단 무시하고 두가지 좋은점을 생각해보자.

### Memory Access Fault의 장점(Implication잠재된 장점)

1. 많은 프로세스가 메인메모리에 올라갈 수 있다.
    - 프로세스의 일부만 올리기 때문에 많은 개수의 프로세스를 올릴 수 있다.
    - 적어도 하나 이상의 프로세스가 준비 상태에 있을 가능성이 커지므로, 프로세서의 활용도 ⬆️
2. 메인메모리보다 큰 프로세스를 수행할 수 있다.
    - 만약 프로그램이 클 경우 오버레이(overlay)와 같은 기법을 존나게 고민해야함.
    - 가상메모리를 이용한 페이징, 세그멘테이션 쓰면 프로그래머가 고민을 안해도돼~~

### Real Mem vs Virtual Mem

- Real Mem : 메인메모리. 실제 RAM(프로세스가 실행되는)
- Virtual Mem : 보조기억장치.
    - 메인메모리마냥 주소를 지정해서 사용할 수 있는 가상메모리.(저장공간 할당체제)
    - Virtual Mem 사용하는 목표
        1. 멀티프로그래밍 효율적으로 할 수 있게함.
        2. 메인메모리보다 큰 프로세스를 수행할 수 있게끔함. → 존나 중요한 목표임.

### Simple Paging(Segmentation) vs Virtual Mem Paging(Segmentation) - 차이점

- Simple Paging(Seg) : Overlay기법을 사용하지 않으면 수행할 프로세스의 모든 페이지나 세그먼트가 메인메모리에 올라와있어야한다.
- Virtual Paging(Seg) :
    - 수행할 프로세스의 모든 페이지나 세그먼트가 메인메모리에 있을 필요가 없음
    - 메인메모리로 하나의 페이지나 세그먼트를 읽어 오기 위해 한 페이지를 디스크에 기록해야 할 수도 있음.
    

### 지역성(Locality)와 Virtual Mem

- 지역성의 원리
    - 프로세스내의 데이터나 명령어는 군집화(Cluster)되어 있다. 모여있다!!
    - 그래서 짧은 시간동안 프로세스의 블록 몇개만 필요할것이다.
    - 왜냐면? Cluster되어있어서 그쪽 부분만 보면 됨 → 그래서 Virtual Mem 쓸 수 있는것.
- Virtual Mem
    - 지역성의 원리때문에 VM을 쓸 수 있다.
    - 메인메모리에 일부만 올려서 쓸 수 있게 됐다.
        - 일부만 올리니까 많은 프로세스를 쓸 수 있게 됐고
        - I/O time을 줄였다. 왜냐면 안쓰는 조각은 안올려놨으니까!
        - 메인메모리의 크기보다 큰 Process를 실행시킬 수 있게 했다.

### 쓰레싱(Thrashing)

- Steady State(안정상태) : 메인메모리 전체가 프로세스 블록들로 채워져 있는 상태.
- Steady State에서 메인메모리에 없는 Piece를 가져오려면 무조건 Swap-out해야함.
- 쓰레싱 : 시스템이 명령어를 실행하는 것보다 Piece들을 Swap하는데 시간을 더 쓰는 상태.
- 이걸 피하려고 OS는 잘 추측을 해서 내보내야함.(최근기록, 많이 쓰이는놈들...이렇게 추측)

### VM을 실용적으로 쓰기위한 2가지 요소

1.  Hardware지원 : VA(virtual address) → PA(physical) 로 바뀔 수 있게 지원해야함.
2. Software 지원 : OS에서 보조기억장치와 메인메모리 사이에서 페이지or세그먼트들이 이동할 수 있게끔 관리하는 놈이 있어야함.(어떤놈이 나가고 어떤놈이 남아있을지 위의 쓰레싱과 관련된 내용)

### Paging-VM

- VM은 일반적으로 세그멘테이션 보단 페이징에 많이 쓰인다.
- 페이징 특징
    1. 각 프로세스는 Page Table을 가진다.
    2. Page Table Entry에는 해당 페이지가 저장된 페이지프레임 번호가 지정된다.
    3. 프로그램들이 컴파일러나 메모리관리 시스템과 맞게끔 Page로 분할됨
    4. OS는 무조건 Free-Frame List를 가짐. (안쓰고있는 List)
- 메인메모리를 Frame으로 자르고 Program도 Page으로 자른다.
- 프로세스의 메모리 공간을 얘기할 때는 **페이지**라 하고, 실제 메모리에서는 **프레임**이라고 한다.

                                           <Virtual Address와 Page Table Entry>

![스크린샷 2022-05-16 19.00.40.png](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_19.00.40.png)

- 원래는 다 올리거나 Overlay로 올렸음
- 근데 VM에서는 일부만 있으니까 현재 MM에 있냐 없냐 이런걸 판단해야함
1. P :  Present Bit
    - 현재 그 페이지가 MM에 있는가 없는가
    - 0이면 없고 1이면 있다
2. M : Modified Bit
    - 만약 Swap out 해서 다시 Secondary Mem으로 돌아갈때 수정사항이 있으면 1
    - 수정사항이 없으면 0 → Write가 필요 없음.
    - 만약 1이면 디스크에 Write를 해야함.
3. Other Conrol Bit
    - 뭐.. Protection, Sharing이런거 있음
    - Read-only, Write-only...등등

### 페이징 시스템에서의 주소변환

![IMG_E4657D9EAF38-1.jpeg](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/IMG_E4657D9EAF38-1.jpeg)

### 페이지 테이블을 구성하기 위한 2단계 구조

![IMG_296B3485F68C-1.jpeg](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/IMG_296B3485F68C-1.jpeg)

- 32bit로 → 1바이트를 나타낸다.
- 그래서 2^32bytes를 나타낼 수 있음. 32bit로!
- 2^12(4K)-bytes Page Size를 가정. == 한 페이지당 4K Size를 가짐.

- 그러면 2^20개의 Page를 표현할 수 있음.
- 32비트를 그래서 2^20(페이지개수)    2^12(페이지내용, 데이터) 로 나눠서 쓸 수 있음.
- 바이트로 표현하면 2^32(4GB)짜리 Virtual Address Space를 가진다.
- 2^20개 페이지 각각을 나타내는 PTE(page table entry)이 4byte라고 가정하면
- 2^20개의 페이지 테이블은 2^22(4MB)이다.
- 이 페이지 테이블을 또 페이지로 나눠보자.
- 2^22(4MB) 를 2^12사이즈를 가지는 페이지들로 나눠보면 2^10개의  페이지들로 나타낼 수 있음
- 2^10개의 페이지 각각이 가지는 PTE가 4byte라면
- 2^12(4KB) 사이즈를 가지는 Page Table을 구할 수 있다. 바로바로 이놈을 ! Main Memory에 넣는다면!
- 4GB짜리 Address Space를 4KB짜리 Page Table로 표현 가능하다!
- 이런식으로 2단계의 구조로 Size를 확 줄여버린다.
- 꼭꼭 복습해라 꼭!

 과정.

![IMG_CBF5699CFCD4-1.jpeg](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/IMG_CBF5699CFCD4-1.jpeg)

## Inverted Page Table(역페이지 테이블)

### Multiple-Level Page Table의 문제점(위에서 본것)

- Virtual Address Space의 크기에 따라 Page Table들이 증가한다.
- 이러면 32bit로 했으면 4K로 줄일 수 있었지만 64bit로 해버리면 진짜 존나증가함 4T임 ㅋㅋ
    - 64bit 주소 체계에서는 4KB 페이지가 2^52개이다.
    - ex) 32bit 주소 체계에서 페이지 크기가 4KB일때는 페이지 개수는 2^20개였지만,
    
    ⇒ 1P * 4byte를 다음 레벨로 페이징하더라도 2^40 * 4byte = 4TB
    

### Inverted Page Table

- Inverted Page Table(구성요소)
    1. Page Number : VA에서의 Page Number
    2. Process Identifier : Page가 속한 Process의 ID
    3. Control Bits : 위에서의 Modifiy됐는지 안됐는지, Control Bit이런거.
    4. Chain Pointer : 체인에서 다음 Entry 의 인덱스 값.
- VA에서 페이지 넘버는 간단한 Hash함수를 통해 Hash Value(해시값)으로 mapping된다.
- 해시값은 역페이지 테이블에 대한 인덱스로 쓰인다.
- Page Entry : Real memory → interved page table
    
    (가상 페이지 → Real 페이지 x  ⇒ 위에서 살펴본 Multiple-Level Paging System)
    
    ⇒ Real 메모리의 크기에 따라 페이지 테이블의 크기가 결정된다.
    
- 문제점
    
    많은 Virtual Page들이 해시되어 메인메모리의 프레임과 매핑된다.
    
    → 같은 곳(hash table entry)에 매핑될 수 있음 = 충돌
    
    충돌을 해결하기 위해서 체인 기술이 사용된다.
    

**역페이지 테이블이라고 하는 이유**

Virtual page number → Frame number의 역방향인

Frame number → Virtual page number 이기 때문에 역 페이지 테이블이라고 한다.

![스크린샷 2022-05-16 03.51.34.png](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_03.51.34.png)

- n > m이다 (VS는 메인메모리보다 크니까)
- h(i)=h(j), i≠j인 경우 충돌 발생

- 체인을 통해서 충돌 해결

![스크린샷 2022-05-16 21.49.46.png](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_21.49.46.png)

1. vpn(Virtual Page Number)를 해시를 통해 테이블 인덱스를 찾는다. → 0x0
2. 해당 인덱스의 프레임으로 가서 PID를 비교한다.
    
    → 프레임에 기록된 PID와 다르다
    
3. Next를 보고 다음 체인으로 이동한다. → 0X18F1B
4. PID가 0이고, VPN이 0x1로 일치하므로 ppm(physical page number)를 찾았다!
    
    ppm = 0x18F1B
    
    ⇒ real address = ppm + offset
    

(만약 일치하지 않으면 다음 체인으로 이동할 것)

## Translation Lookaside Buffer (TLB)

---

- TLB가 필요한 이유
    
    가상 메모리 참조는 두 번의 물리적 메모리 접근이 필요하다
    
    1. PTE에 접근하기 위해서
    2. DATA를 불러오기 위해서
    
    ⇒ memory access time이 두 배가 되는 현상을 극복하기 위해서 특별한 high-speed 캐시를 사용한다. 
    == TLB(Translation Lookaside Buffer)
    

- TLB란
    - 메모리 캐시와 같은 개념이다.
    - 최근에 사용된 PTE들이 포함되어 있다.

### TLB의 도식화

![스크린샷 2022-05-16 04.06.37.png](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_04.06.37.png)

1. TLB에서 일치하는 페이지 번호가 있는지 확인
    - TLB hit
        
        → 프레임 번호를 얻게 된다.
        
    - TLB miss
        
        → 메인메모리의 페이지 테이블에 접근
        
        → 프레임 번호를 얻게 된다.
        
2. 메모리에 해당 페이지가 있는지 확인
    
    Page Fault(P=0)
    
    → 보조기억장치에서 해당 페이지를 메인메모리에 적재 후 다시 진행
    
    Page hit(P=1)
    
    → TLB에 해당 PTE를 저장한다.
    

### TLB의 순서도

![스크린샷 2022-05-16 04.12.39.png](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_04.12.39.png)

### Associative Mapping(연관 매핑)

TLB는 PTE(Page Table Entry)의 일부만 올라가 있음.

따라서 TLB를 인덱싱해서 바로 사용할 수 없으며, TLB는 (PTE + page number)로 이루어진다.

프로세서에는 특정 페이지 번호와 일치하는 TLB를 결정하기 위해 여러 TLB들을 동시에 조사해서 페이지 번호를 찾을 수 있는 하드웨어가 장착되어 있다.

![스크린샷 2022-05-16 13.59.25.png](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_13.59.25.png)

- Direct mapping
    
    : 인덱스를 기반으로 찾는 것
    
    : 페이지 테이블에서 해당 인덱스를 바로 찾으면 된다.
    
    : 여기선 5번 인덱스를 바로 찾아감.
    
- **Associative mapping(TLB)**
    
    : TLB들을 동시에 확인하는 하드웨어를 통해 각 페이지 #에 해당하는 PTE를 찾는다.
    : 만약 저기 없으면 TLB Miss가 나서 페이지 테이블로 접근할 것이다.
    : 그 이후는 흐름도 참조.
    
    - direct mapping은 index가 따로 없고 순서로 파악. associative는 page#를 통해 딕셔너리처럼 찾아버린다.

### TLB와 캐시를 이용한 흐름

![스크린샷 2022-05-16 14.02.40.png](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_14.02.40.png)

1. 주어진 VA에서 해당 페이지 번호가 TLB에 있는지 찾는다.
    
    TLB miss일 경우 페이지 테이블에서 찾는다.
    
2. 프레임 번호 + offset → 실제 주소를 찾는다.
3. 캐시에 실제 주소의 값이 적재되어 있는지 찾는다.
    
    캐시 miss일 경우 메인 메모리에서 해당 값을 찾는다.
    

만약 TLB hit & 캐시 hit → 메모리 접근을 한 번도 안하고 값을 찾을 수 있다.

### 페이지 크기 - 하드웨어 설계에서 아주 중요한 ISSUE

- 페이지 크기를 결정할 때 고려할 요소 3가지.
    1. 내부 단편화를 줄여야 한다 → 메모리 사용을 최적화하기 위해.
        - 페이지 크기를 줄이면 내부 단편화를 줄일 수 있다.
            
            → 많은 페이지들이 만들어져서 페이지 테이블이 커진다.
            
    2. 페이지 폴트를 줄여야 한다.
        - 대형 프로그램일수록 페이지 테이블의 일부가 가상 메모리에 있을 것이다.
            
            → 메모리 참조 과정에서 페이지 테이블을 찾기 위해서 페이지 폴트가 두 번 발생
            
            (첫번째 폴트로 페이지테이블의 일부를 반입, 두번째 폴트로 프로세스 페이지의 반입)
            
    3. 블록 변환을 효율적으로 해야 한다.
        - 보조기억장치에서 정보를 찾는데는 고정적으로 시간이 많이 걸리므로 seek를 최소화 하는 것이 좋다.
            
            ⇒ 페이지 크기가 큰 것이 seek를 줄일 수 있다 (한 번에 많이 가져오니까)
            

- 페이지 크기에 따른 추가적인 고려사항들
    - 메인 메모리 크기가 커지면서 주소 공간이 커지고, 이에 따라 응용프로그램의 복잡도가 증가
    - 프로세스의 메모리 크기가 커지면서 지역성이 감소하면 TLB hit율이 감소한다.
    - 그러면 TLB hit를 높이기위해선? TLB의 크기를 키우면된다.
        - 그럼 TLB의 크기를 키우는 방법은? → TLB의 크기는 메인 메모리 크기의 증가를 못 따라잡는다.
        - 페이지 크기를 키워서 TLB의 항목이 더 큰 메모리 블록을 가리킬 수 있도록 하는 방법은? → 지역성이 감소해서 결국 PFR이 올라간다.
    - 따라서 여러 페이지 크기(multiple page size)를 지원하는 방법은?(해결책)
        - TLB를 효율적으로 사용하기 위해서 유연한 방법을 제공할 수 있다.
        - 하지만 OS에서 고려할 사항이 많기 때문에 여러 페이지 크기를 지원하는 것은 힘들다
            
            ⇒ 대부분 상용 OS에서는 단일 페이지 크기를 사용한다.
            
    
- 다양한 페이지 크기의 예시
    
    ![스크린샷 2022-05-16 15.03.42.png](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_15.03.42.png)
    
    Pentium, Itanium 같이 하드웨어별로 다양한 페이지 크기를 지원하더라도
    
    OS에서는 단일 페이지 크기를 사용한다.
    

## Segmentation in VM

---

Segmentation은 프로그래머가 프로그램 특성/구조에 맞는 다양한 크기의 Segment로 나눠서 관리할 수 있다.

- 장점
    1. 데이터 구조에 맞는 다양한 크기를 할당 → 데이터 구조가 확장되어도 다루기 쉽다
    2. 프로그램이 모듈화 →  독립적으로 재컴파일할 수 있다.
    3. 프로세스들이 세그먼트를 공유 → 프로세스 간 데이터 공유 용이
    4. 세그먼트를 보호할 수 있음. → 각 세그먼트안의 내용을 프로그래머가 구성할 수 있어서 자신에게 용이한 방식으로 접근 권한을 부여할 수 있음.

### 세그먼트(가변)의 구성.

세그먼트 테이블의 entry - 프로세스마다 고유의 세그먼트테이블을 갖는다.

- starting address (메인메모리에서의 시작주소)
- legnth (세그먼트의 길이)

- control bits(Simple세그먼트와의 차이점)
    - Present : 메인메모리에 이미 존재하는지 여부
    - Modified : 수정되었는지 여부
    - 기타 : protection, sharing 정보 등

<세그멘테이션에서의 주소변환>

![스크린샷 2022-05-16 15.11.54.png](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_15.11.54.png)

1. 레지스터의 세그먼트 테이블 포인터 + 세그먼트 번호 → 세그먼트 테이블 entry 접근
2. 세그먼트의 Length와 offset(=d)을 비교해서 L>d 인 경우에만 접근 가능
3. 세그먼트 Base (시작주소) + (Offset) d → 실제 주소로 접근

## 페이징과 세그먼트의 혼합 방식

---

- user address space는 세그먼트 단위로 나눠진다.
    - 세그먼트는 프로그래머가 볼 수 있다.
        
        ⇒ 다양한 자료 구조를 쉽게 다룰 수 있고, Sharing과 Protection을 지원할 수 있다.
        
- 세그먼트 내부에서는 고정 길이 페이지로 나눠진다.
    - 페이징은 우리 눈에 보이진 않는다.
    - 페이징은 외부 단편화가 없다.
        
        ⇒  메인메모리를 효율적으로 사용할 수 있다
        
    - 페이지 크기와 프레임 크기가 같다.
        
        ⇒ 정교한 메모리 관리 정책을 사용할 수 있으며, 매핑이 수월하다.
        

![페이징과 세그먼트 혼합 방식에서의 주소 변환](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_15.37.52.png)

페이징과 세그먼트 혼합 방식에서의 주소 변환

- VA는 (세그먼트 번호, 페이지 번호, 오프셋)으로 구성된다.
    1. 세그먼트 테이블을 이용해서 세그먼트 번호에 해당하는 페이지 테이블을 찾는다.
    2. 페이지 테이블을 이용해서 페이지 번호에 해당하는 프레임 번호를 얻는다
    3. 프레임 번호 + offset → 실제 주소를 얻는다.
    
- 단점
    - 메인 메모리를 3번 접근해야 한다.(Segmentation Mechanism, Pagign Mechanism, Main Memory)

<결합방식에서의 Table 구조>

![스크린샷 2022-05-16 15.41.14.png](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_15.41.14.png)

- VA : 세그먼트 번호, 페이지 번호, 오프셋
- STE : control bits, length, segment base (페이지 테이블의 시작 주소를 가리킴)
- PTE : P, M, 나머지 control bits, 프레임 번호
    
    P는 메인메모리에 위치한지 여부, M은 값이 수정되었는지 여부
    

### Protection and Sharing

- Segmentation을 이용했을 때 보호와 공유를 구현하기 적합하다.
    
    세그먼트가 프로그래머에게 visible하니까!
    
    - 보호 : 세그먼트테이블의 각 항목(Entry)에는 base address와 length를 가지기 때문에 허용되지 않는 영역에 침범하는 것을 막을 수 있다.
    - 공유 : 여러 개의 프로세스의 세그먼트 테이블에 참조하려는 세그먼트의 주소를 넣기만 하면 공유가 가능하다.
- Paging을 이용했을 때 보호와 공유를 구현하기 위해서는 어렵다.
    
    페이지는 프로그래머에게 visible하지 않으므로!
    

![세그먼트 간의 보호 관계](VM-%20Hardware%2096cf55f0bca541e7987df7c6425bdbd6/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-05-16_15.47.06.png)

세그먼트 간의 보호 관계

- 다른 프로세스의 명령어 부분에 접근 → 허가 x
- 다른 프로세스의 데이터 참조
    - 참조가 허용되지 않은 데이터 → 허가 x
    - 참조가 허용된 데이터 → 허가 o

⇒ 이런 방식으로 보호와 공유 모두 제공한다.