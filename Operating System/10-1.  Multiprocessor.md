# Ch 10-1. Multiprocessor

### 멀티프로세서 시스템의 분류

1. 약결합 (Loosely coupled or distributed) 멀티프로세서 (cluster)
    
    : 각 메모리와 IO 채널을 가지는 독립적인 시스템들의 집합
    
2. 강결합 멀티프로레서
    
    : 메모리를 공유하고 하나의 OS로부터 제어되는 프로세서의 집합
    
3. 특수 목적 프로세서
    
    : Master 프로세서가 있고, 특수목적 프로세서는 마스터에 의해 제어된다.
    
    : Master 메인 컨트롤.. Slave프로세서는 명령을 받는다.
    

### Granularity(동기화 단위)

Work에 의해 수행되는 작업의 양 측정

실행되는 명령어 (instruction)의 수로 측정된다.

- Fine(소형) : < 20
    
    단일 명령어 스트림에 포함된 단위
    
- Medium(중형) : 20 ~ 200
    
    단일 애플리케이션에 포함된 단위
    
- Coarse(대형) : 200 ~ 2000
    
    여러 애플리케이션
    
- Very Coarse(특대형) : 2000 ~ 1M
    
    단일 컴퓨팅 환경처럼 보이면서 네트워크 노드를 통해서 실행되는 환경
    
    네트워크로 연결된 여러 기계들이 단일 컴퓨팅 환경처럼 보이게 해주는 분산처리 시스템을 지원.
    
- Independent
    
    아무 연관 없는 프로세스 간의 단위
    

### 독립적 병렬성 (Independent Parallelism) → 동기화 필요 X

- 애플리케이션 또는 job이 독립적이다.
- 프로세스 간 명시적인 동기화가 필요하지 않다.
- 시분할(Time Sharing) 시스템에서 많이 사용된다.
- 각각의 User들이 어플리케이션을 독립적으로 수행한다.
- 하나 이상의 프로세서를 사용.(멀티프로세서..) 
→ 여러 개의 프로세서가 동시에 서비스를 해주기 때문에 여러 사용자들의 요청을 병렬적으로 서비스 할 수 있어 평균 응답시간 낮아짐.

### Coarse & Very Coarse Grained Parallelism → 동기화 필요 O

- 큰 단위 (ex 애플리케이션)의 프로세스 간 동기화가 사용된다.
- 동기화의 단위가 상당히 크다!!
- 단일 프로세서의 멀티프로그래밍에서 수행되는 것처럼 시스템 내부의 큰 프로세스 집합들 간의 동시성을 지원한다. → Concurrent(병렬성) 지원. → 인터리빙
- 소프트웨어의 변경을 거의 하지 않고 시스템에서 인터리빙, 오버래핑을 사용할 수 있다. → 멀티프로세서의 기능.

- 그렇다면 Coarse 시스템에서는 어떤 아키텍처를 사용해야 하는가?
    1. 프로세스 간의 상호작용이 자주 발생하는 경우 : 멀티 프로세서 
    2. 프로세스 간의 상호작용이 드물게 발생하는 경우 : 분산처리 시스템
        - 한 번에 작업을 모아서 처리하는 분산처리 시스템이 좋은 성능을 낼 수 있다.
        - 만약 상호작용이 자주 발생한다면 분산 시스템의 네트워크 지연으로 인해 성능이 감소한다.

### Medium-Grained Parallelism → 프로그래머 책임

: 단일 프로세스(애플리케이션) 내부에서 스레드 단위의 병렬처리

- 책임 : 프로그래머
    
    스레드 간 동기화 및 상호작용은 프로그래머가 명시해서 제어한다.
    

- 애플리케이션 내부에서 스레드들의 상호작용은 빈번하게 발생 → 쓰레드의 스케줄링이 애플리케이션 성능에 큰 영향을 미친다.

### Fine-Grained Parallelism → 컴파일러 책임

: 단일 명령어 스트림 내의 병렬 처리

- 스레드 단위의 병렬처리보다 훨씬 복잡하다. (기계어 묶음 단위로 병렬처리 해야한다)
- 책임 : 컴파일러
    
    프로그래머가 이러한 병렬처리를 지원하기는 매우 어렵다
    

## 멀티프로세서 스케줄링 설계 이슈

---

1. 프로세스를 어떤 프로세서에 할당할 것인가?
2. 개별 프로세서에 멀티프로그래밍(인터리빙)을 지원할 것인가?
3. 다음 프로세스로 어떤 것을 Dispatch할 것인가?

→ Granularity(동기화 단위)의 정도에 따라 결정된다!!

- 설계의 의존성
    - 애플리케이션의 세분화 정도
    - 사용 가능한 프로세서 수

### 1-1. 프로세서에 프로세스 할당: 어디에?

가정 : 모든 프로세서의 성능이 동일 → 프로세스를 어디 할당해도 상관없다.

프로세서를 풀로 관리하며 프로세스를 할당한다

- 정적 or 동적할당을 결정해야 한다.
- 런타임에 배정할것(동적)이냐 런타임 전(정적)에 배정할 것이냐

S**tatic Assignment :** 프로세서 ← 프로세스가 영구적으로 할당

⇒ 각각의 프로세서마다 존재하는 **Short-Term Queue**에 들어가서 실행을 기다린다.

- 스케줄링에서 오버해드가 적다
- Group이나 Gang 스케줄링을 이용한다. (이후 설명)

- Static assignment의 문제점(단점)
    
    : 해당 프로세서의 전용 풀에 들어가서 스케줄링을 기다리니까 Idle 프로세서가 있어도 Static하게 할당된 프로세서를 기다린다. → 불균형 발생!
    
    - 해결 방법(Idle한 프로세서가 없도록 어떻게할까?)
        1. Common 큐를 사용한다
        2. Dynamic Load Balancing
            - 다른 프로세서의 큐로 이동시킨다.
            - Linux에서 사용한다.

### 1-2. 프로세서에 프로세스 할당: 어떻게?

1. **Master-Slave 아키텍처**
    - Master 프로세서 : OS의 커널 기능을 담당, Job의 스케줄링 처리
    - Slave 프로세서 : User Program의 실행만 담당. 
    커널 기능이 필요할 때는 (ex IO call) Master 프로세서에게 요청
    
    - 장점
        - 단일프로세서 멀티프로그래밍 OS와 유사한 구조 → 약간의 수정만 하면 된다.
        - Master 프로세서가 모든 것을 담당 →  메모리 및 IO 자원 관리에 대한 충돌을 관리하기 쉽다.
    - 단점
        - Master가 고장나면 시스템 전체가 다운된다.
        - Master에서 병목 현상(Bottleneck)이 생길 수 있다.
2. **Peer 아키텍처(동등한 구조)**
    - 커널을 모든 프로세서에서 실행할 수 있다.
    - 각 프로세서는 스스로 스케줄링(Self Scheduling)한다.
    - 이 때 두 프로세서가 동일한 프로세스를 선택하지 않도록 해야함 → OS가 관리해야 한다.(복잡한 Issue…)
    

> 정리하자면, 
Master-Slave : 커널-Master, 스케줄링-Master , User - Slave 
peer : 커널-All, 스케줄링-All(각 프로세서)
> 

### 2. 개별 프로세서에서 멀티프로그래밍

각 프로세서마다 멀티프로그래밍을 꼭 지원해야할까?

- Coarse-Gained or Independent
    
    애플리케이션 단위로 집합이 이루어져 있으므로 멀티프로그래밍을 지원해야 한다!
    
    → cpu 활용율을 높이기 위해서
    
- Medium-Grained
    
    단일 애플리케이션 내부에서 스레드 단위의 집합으로 이루어져 있으므로
    
    여러 프로세서에 할당해서 병렬 처리 → cpu 활용은 높아질지 몰라도, 애플리케이션의 처리가 늦어진다. (늦은 응답)
    

⇒ 무조건 인터리빙을 하는 것이 능사가 아니라, 병렬 처리를 하는 프로세스의 규모 (단위)를 생각해야 한다.

### 3. 프로세스 Dispatch

- 멀티프로그래밍 단일 프로세서에서는 우선순위나 지난(과거) Use에 기반한 복잡한 스케줄링 알고리즘을 사용했다.
- 멀티프로세서 환경에서는 오히려 단순한 스케줄링을 사용해서 오버헤드를 줄여야 더 효과적일 수 있다.
    - 즉, 우선순위 또는 실행 이력보다 더 중요한 이슈가 있을 것이다 (추후 설명)
    

### 프로세스 스케줄링

전통적인 멀티프로세서 시스템에서는 프로세스가 특정 프로세서에 전용으로 할당되지 않는다.

시스템의 단일 큐 ← 모든 프로세서가 사용.

- 만약 우선순위가 필요하다면 우선순위별로 큐를 만들어 사용한다.

스케줄링 알고리즘 RR, SRT과 가장 기본적인 FCFS의 성능 차이를 단일 프로세서 환경과 멀티 프로세서 환경에서 비교해보고자 한다.

세로축 : FCFS 대비 RR or SRT의 성능 비율

가로축 : (서비스 시간의 표준편차) / (평균 서비스 시간)

![스크린샷 2022-06-11 19.40.14.png](Ch%2010-1%20Multiprocessor%2019e399d424ad4363b829128386e28315/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-11_19.40.14.png)

![스크린샷 2022-06-11 19.40.21.png](Ch%2010-1%20Multiprocessor%2019e399d424ad4363b829128386e28315/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-11_19.40.21.png)

단일 프로세서 환경에서는 RR, SRT 모두 FCFS에 비해 성능 개선이 크지만,

멀티 프로세서 환경에서는 큰 성능의 차이가 없다.

⇒ 스케줄링 알고리즘의 성능 이점보다 오버헤드가 더 발생할 수 있다.

### 스레드 스케줄링

애플리케이션은 동일한 주소 공간(address space)를 동시에 실행되면서 서로 협력하는 스레드들의 집합이다.

- 단일 프로세서 (오버래핑) : 스레드는 
프로그램을 만드는데 사용되는 구조화 수단이거나, 
IO Overlap 처리를 위한 수단(IO 콜로 블락되면 다음 스레드 실행) 정도로만 사용했다.
- 멀티 프로세서 (인터리빙) : 스레드들이 여러 프로세서에서 동시에 실행되기 때문에 진정한 병렬 처리
    
    → 단일 프로세서 환경보다 스레드 동시성으로 얻는 성능의 이득이 훨씬 크다.  
    
    ⇒ 따라서 스레드 스케줄링과 관리가 단일 프로세서 환경보다 훨씬 중요하다. (성능에 미치는 영향이 크다)
    
    ⇒ Medium Grain Parallelism은 쓰레드간 통신이 매우 빈번하게 발생하기 때문에 이 쓰레드 스케줄링이 상당히 중요하다
    

### 스레드 스케줄링에 대한 접근법

1. **Load Sharing (부하 공유)**
    - 프로세스가 특정 프로세서에 할당되지 않는다.
    - 프로세스가 시스템의 전역적인(Global) 큐에 들어간다.
    - 프로세서가 유휴(Idle) 상태일 때 Global 큐에서 대기중인 스레드를 선택해서 실행한다.
2. **Gang Scheduling (조직 스케줄링) : 동시간에 실행**
    - 연관 관계가 있는 스레드를 집합으로 묶고, 프로세서도 집합으로 묶는다.
    - 두 집합을 **동시간**에 1:1 매칭해서 실행한다.
3. **Dedicated Processor Assginment (전용 프로세서 할당)**
    - 각 프로그램은 실행 시간동안 프로그램의 쓰레드 수만큼 동일한 수의 프로세서를 할당받는다.
    - 프로그램이 종료되면 할당되었던 프로세서들은 다시 일반 풀로 돌아간다.
4. **Dynamic Scheduling (동적 스케줄링)**
    - 실행하는 동안 프로세서에 할당된 쓰레드 수가 변경될 수 있다.
    

### 1. Load Sharing (부하 공유)

단일 프로세서 환경을 거의 그대로 사용하면 되는 가장 간단한 방식(인터리빙되던걸 오버래핑되게끔만 하면됨)

멀티 프로세서에서 가장 일반적으로 사용되는 방식

- Load Sharing의 세가지 버전
    1. FCFS- 먼저 들어온 쓰레드 우선방식 (비선점- 한번 수행되면 완료 or block될때까지 안풀림)
    2. 가장 스레드가 적은 프로세스 먼저 (비선점)
    3. 가장 스레드가 적은 프로세스 먼저 (선점)
        
        수행 도중에 자신보다 쓰레드가 적은 프로세스가 요청되면 선점된다.
        
    
- 장점
    - 프로세서에 걸리는 부하가 균등하게 분산된다. → 유휴 상태의 프로세서가 최소화
    - 중앙 집중식 스케줄러가 없다 : 특정 프로세서가 스케줄링을 전담하는 것이 아니라 각 프로세서가 풀에서 직접 선택하는 방식
    - 전역(Global) (프로세스) 큐를 사용하므로 우선순위, 실행 이력(used), 예상되는 요구량 등 다양한 체계를 사용해서 스케줄링을 지원할 수 있다.

- 단점
    - 메모리 접근의 병목 현상
        
        : 모든 프로세서가 단일 프로세스 큐에서 선택한다.
        
        → 해당 큐에서의 상호배제를 지키면서 접근하다보니 병목 현상이 발생한다.
        
        → 만약 여러 프로세서들이 스케줄할 쓰레드를 고르기위해 Global 큐에 존나 많이 접근하게 되면 Mutual Exclusion때문에 병목현상이 일어날 수 있다. 
        
    - 캐시의 효율성이 감소
        
        : 선점 모드에서 프로세서A가 캐시에 프로세스 p에서 필요한 자원 중 일부를 저장해놨는데 인터리빙 과정에서 다른 프로세서B가 프로세스 p를 실행한다.
        
        → A의 캐시를 활용하면 p를 효율적으로 실행할 수 있는데 A가 아닌 프로세서 B가 프로세스 p를 실행하면서 캐시의 효율성이 떨어진다
        
    - 성능 저하
        
        프로세서가 선택해서 실행할 때까지 스레드가 실행되지 않는다
        
        → 프로그램에서 스레드간 많은 상호작용이 필요할 때 자꾸 대기상태가 되기 때문에 성능이 저하된다.
        

### Gang Scheduling (조직=갱 스케줄링)

: 단일 프로세스를 구성하는 여러 쓰레드들을 동시에 스케줄링

: 하나의 프로그램을 구성하는 여러 개의 쓰레드를 동시에 여러개의 처리기로 스케줄링하는 방식.

- 이익
    - 성능 향상
        
        스레드 간 동기화 과정에서 block되는 것을 줄일 수 있다
        
        → 그에 따른 필요없는 프로세스 context switching도 줄일 수 있다.
        
    - 스케줄링 오버헤드 감소
        
        단일 스케줄링을 사용하면 여러 프로세서와 프로세스에 영향을 주는데,
        
        집합으로 나눠서 관리를 하니 이 과정에서 발생하는 오버헤드를 줄일 수 있다
        

- 스레드 단위의 스케줄링이므로, **medium-grained(중규모) 또는 fine-grained(소규모) 수준의 병렬처리에서 유용**하다.(특히 medium에 적합하다!!)
    
    앞서 중규모 (단일 애플리케이션)의 병렬처리에서는 인터리빙으로 인해 오히려 성능이 감소할 수 있다고 했는데, 그룰 해결하기 위한 방법이다.
    
- 가정
    
    프로세서 수 = N, 애플리케이션 수 = M
    
    각 애플리케이션은 N개 이하의 스레드를 가진다.(프로세서의 수보다 작은 개수의 쓰레드를 갖는다)
    
    두 애플리케이션 A(4 스레드), B(1 스레드)가 있다.
    
    ![스크린샷 2022-06-11 20.20.36.png](Ch%2010-1%20Multiprocessor%2019e399d424ad4363b829128386e28315/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-11_20.20.36.png)
    
    - **균일한 스케줄링**
        
        : 각 애플리케이션은 1 / M의 시간만큼 프로세서에서 time slice를 가진다.
        
        이 때 1/2 * 3/4 = 37.5%의 자원(프로세서 시간) 낭비가 발생한 것을 볼 수 있다.
        
    - **가중치 스케줄링**
        
        : 스레드 개수만큼 time slice를 할당 받는다.
        
        A는 스레드 4개이니까 4개의 time slot을 할당, B는 1개의 time slot을 할당 받은 것을 볼 수 있다.
        
        이 때 1/5 * 3/4 = 15%만큼의 자원 낭비가 발생한 것을 볼 수 있다. → 더 효율적
        

### Dedicated Processor Assignment (전용 프로세서 할당, 쓸 수 있는 프로세서가 너무많다.)

: 갱스케쥴링을 극단적으로 사용 하는 방법.

: 애플리케이션의 각 스레드는 종료될 때까지 할당 받은 프로세서에 남아있는다.

(갱 스케줄링 + 비선점의 개념)

- 스레드가 IO나 동기화를 위해 쓰레드가 블락되면 할당된 프로세서는 Idle 상태로 기다린다. (멀티프로그래밍 X)
    
    → 음 그러면 성능이 안좋은 것 아닌가?라는 의문이 들 수 있는데 이 전략은 일반적인 경우에 사용하는  것이 아니다.
    
- 고도로 병렬화된 시스템 (수십 ~ 수백개의 프로세서가 존재)에서는 남아도는 것이 프로세서이므로 프로세서 하나의 활용도는 크게 중요하지 않다.
    
    ⇒ 프로세스 스위칭이 일어나지 않도록 프로세서를 전용 할당하는 것이 성능이 더 향상된다.
    

![스크린샷 2022-06-11 21.48.01.png](Ch%2010-1%20Multiprocessor%2019e399d424ad4363b829128386e28315/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-11_21.48.01.png)

16개의 프로세서를 가지는 시스템에서 두 애플리케이션의 실행 성능을 비교한 것이다.

스레드가 증가할 수록 성능이 증가하여 스레드 수 = 프로세서 수일 때 최대치를 보인다. (8 * 2 = 16)

스레드의 전체 수가 프로세서 수를 넘는 순간 선점과 스케줄링에 의해 성능 저하가 일어난다.

⇒ 활성 스레드 수를 프로세서 수 이하로 제한하는 것이 좋다.

⇒ 수행되고 있는 쓰레드의 수를 처리기 수 이하로 제한!→ 성능 굳

### Dynamic Scheduling (동적 스케줄링)

: 프로세스의 스레드 수를 동적으로 변경 → OS가 부하를 조정하여 활용도를 높인다.

- OS와 애플리케이션 모두 스케줄링 결정에 참여한다.
    - OS는 프로세서들을 분할하여 작업들에게 적절히 나누어주는 역할
    - OS는 런타임 라이브러리를 제공하여 스케줄링할 수 있도록 지원한다.
    - 몇 개의 스레드를 사용할 것인지는 애플리케이션이 결정한다. (라이브러리 사용)
        - 만약 라이브러리를 사용하지 않으면 기본적으로 단일 스레드로 처리된다.
        - 라이브러리를 사용하면 동적으로 사용 할 수 있다.
        - 여러 태스크 중 어느 것을 우선적으로 쓰레드화 할것인지에 대한 책임은 애플리케이션이한다!
        
- Job이 프로세서를 요구할때
    1. 만약 Idle 프로세서가 있다면 이를 사용한다.
    2. Idle 없다면 2개 이상의 프로세서가 할당된 job에서 1개의 프로세서를 뺏어서 할당한다.
    3. 이 과정을 했는데도 요청을 충족할 수 없다면 큐에서 대기한다.
    4. 프로세서가 릴리즈될 때 큐에서 대기중인 job에게 프로세서를 할당한다. (FCFS)
        1. 한 개의 프로세서도 할당받지 못한 job에 대해서 먼저 할당한다.
        2. 그리고 먼저 들어온 놈 먼저 할당해주는 방식(FCFS)
    

### 멀티코어 스레드 스케줄링

칩 당 코어 수가 증가함에 따라 프로세서 활용도를 높이는 것보다 off-chip (칩 밖의) 메모리에 대한 액세스를 최소화하는 것이 더 중요하다.

- AMD Bulldozer과 같은 칩에서는 다음과 같은 캐시 구성을 가지는데, 캐시가 공유되므로 문제를 다루기 어렵다.
    
    ![스크린샷 2022-06-11 22.21.15.png](Ch%2010-1%20Multiprocessor%2019e399d424ad4363b829128386e28315/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-11_22.21.15.png)
    
    - 각 코어는 L1 캐시를 가진다.
    - 한 쌍의 코어는 L2 캐시를 공유한다.
    - 모든 코어는 L3 캐시를 공유한다.

- 두 개의 스레드가 메모리 자원을 공유하는 경우 인접한 코어에 할당해서 지역성의 효과를 높인다.
    
    L2 캐시를 공유하니까!
    
- 메모리 자원을 공유하지 않는다면 인접하지 않은 다른 쌍의 코어에 할당함으로써 로드 밸런싱을 구현한다.